Comp_data$TargetLoc <- factor(Comp_data$TargetLoc)
summary(Comp_data$TargetLoc[Comp_data$ID=="1"])
Comp_BadTrialOrder<-ddply(Comp_data, c("ID"), summarise,
Bad = identical(Comp_TrialOrderTestVector, TargetLoc))
summary(Comp_BadTrialOrder)
Comp_data <-read.csv("S:/R-MNHS-SPP/Bellgrove-data/CogBattery_UQ&Monash/AllParticipantData_comp.csv", header=T)
#Remove rows with missing values
Comp_data<-Comp_data[Comp_data$TargetLoc!="",]
Flanker_data<-Flanker_data[Flanker_data$PreGoLabel!="",]
Cueing_data<-Cueing_data[Cueing_data$TargetName!="",]
StopSignal_data<-StopSignal_data[StopSignal_data$PreGoLabel!="",]
#Make the required factors:
Comp_data$TargetLoc <- factor(Comp_data$TargetLoc)
Cueing_data$TargetName <- factor(Cueing_data$TargetName)
StopSignal_data$PreGoLabel <- factor(StopSignal_data$PreGoLabel)
Flanker_data$PreGoLabel <- factor(Flanker_data$PreGoLabel)
#Set up the bad trial order test vectors for each block:
Comp_TrialOrderTestVector<-Comp_data$TargetLoc[Comp_data$ID=="507"]
Comp_TrialOrderTestVector2 <- factor(Comp_block$TargetLoc)
identical(Comp_TrialOrderTestVector,Comp_TrialOrderTestVector2)
Flanker_TrialOrderTestVector <- factor(Flanker_block$PreGoLabel)
Cueing_TrialOrderTestVector <- Cueing_data$TargetName[Cueing_data$ID=="507"]
Cueing_TrialOrderTestVector2 <- factor(Cueing_block$TargetName)
identical(Cueing_TrialOrderTestVector,Cueing_TrialOrderTestVector2) #just out of interest, test if these are identicle
StopSignal_TrialOrderTestVector <- StopSignal_data$PreGoLabel[StopSignal_data$ID=="507"]
StopSignal_TrialOrderTestVector2 <- factor(StopSignal_block$PreGoLabel)
identical(StopSignal_TrialOrderTestVector,StopSignal_TrialOrderTestVector2) #just out of interest, test if these are identicle
#Check to make sure the data have all the same factor levels as TrialOrderTestVectors (and no extra levels)
summary(Comp_data$TargetLoc[Comp_data$ID=="1"])
summary(Comp_TrialOrderTestVector)
Comp_TrialOrderTestVector<-Comp_data$TargetLoc[Comp_data$ID=="507"]
Comp_TrialOrderTestVector2 <- Comp_block$TargetLoc
identical(Comp_TrialOrderTestVector,Comp_TrialOrderTestVector2)
summary(Comp_data$TargetLoc[Comp_data$ID=="1"])
summary(Comp_TrialOrderTestVector)
Comp_BadTrialOrder<-ddply(Comp_data, c("ID"), summarise,
Bad = identical(Comp_TrialOrderTestVector, TargetLoc))
summary(Comp_BadTrialOrder)
Comp_TrialOrderTestVector<-Comp_data$TargetLoc[Comp_data$ID=="507"]
Comp_TrialOrderTestVector2 <- Comp_block$TargetLoc
identical(Comp_TrialOrderTestVector,Comp_TrialOrderTestVector2)
summary(Comp_data$TargetLoc[Comp_data$ID=="1"])
summary(Comp_TrialOrderTestVector)
summary(Comp_TrialOrderTestVector)
summary(Comp_TrialOrderTestVector2)
Comp_TrialOrderTestVector2 <- factor(Comp_block$TargetLoc)
summary(Comp_TrialOrderTestVector2)
identical(as.numeric(Comp_TrialOrderTestVector),as.numeric(Comp_TrialOrderTestVector2))
as.numeric(Comp_TrialOrderTestVector)
as.numeric(Comp_TrialOrderTestVector2)
Comp_TrialOrderTestVector<-Comp_data$TargetLoc[Comp_data$ID=="507"]
Comp_TrialOrderTestVector2 <- factor(Comp_block$TargetLoc)
identical(as.numeric(Comp_TrialOrderTestVector),as.numeric(Comp_TrialOrderTestVector2))
Flanker_TrialOrderTestVector <- Flanker_data$PreGoLabel[Flanker_data$ID=="507"]
summary(Flanker_data$PreGoLabel[Flanker_data$ID=="1"])
summary(Flanker_TrialOrderTestVector)
Flanker_BadTrialOrder<-ddply(Flanker_data, c("ID"), summarise,
Bad = identical(Flanker_TrialOrderTestVector, PreGoLabel))
summary(Flanker_BadTrialOrder)
summary(Comp_BadTrialOrder)
summary(Flanker_BadTrialOrder)
Flanker_TrialOrderTestVector <- factor(Flanker_block$PreGoLabel) #Hayley didn't tell me a participant with bad trial order
summary(Flanker_BadTrialOrder)
Flanker_TrialOrderTestVector <- factor(Flanker_block$PreGoLabel) #Hayley didn't tell me a participant with bad trial order
Flanker_TrialOrderTestVector <- factor(Flanker_block$PreGoLabel) #Hayley didn't tell me a participant with bad trial order
Cueing_TrialOrderTestVector <- Cueing_data$TargetName[Cueing_data$ID=="507"]
Cueing_TrialOrderTestVector2 <- factor(Cueing_block$TargetName)
identical(Cueing_TrialOrderTestVector,Cueing_TrialOrderTestVector2) #just out of interest, test if these are identicle to the bad-trial-order hayley sent
#...it is!
StopSignal_TrialOrderTestVector <- StopSignal_data$PreGoLabel[StopSignal_data$ID=="507"]
StopSignal_TrialOrderTestVector2 <- factor(StopSignal_block$PreGoLabel)
identical(StopSignal_TrialOrderTestVector,StopSignal_TrialOrderTestVector2) #just out of interest, test if these are identicle
#...it is!
#Check to make sure the data have all the same factor levels as TrialOrderTestVectors (and no extra levels)
summary(Comp_data$TargetLoc[Comp_data$ID=="1"])
summary(Comp_TrialOrderTestVector)
summary(Cueing_data$TargetName[Cueing_data$ID=="1"])
summary(Cueing_TrialOrderTestVector)
summary(Flanker_data$PreGoLabel[Flanker_data$ID=="1"])
summary(Flanker_TrialOrderTestVector)
summary(StopSignal_data$PreGoLabel[StopSignal_data$ID=="1"])
summary(StopSignal_TrialOrderTestVector)
#Comp
Comp_BadTrialOrder<-ddply(Comp_data, c("ID"), summarise,
Bad = identical(Comp_TrialOrderTestVector, TargetLoc))
write.csv(summary, file = "Comp_BadTrialOrder.csv") #save for Beth
summary(Comp_BadTrialOrder)
#Flanker
Flanker_BadTrialOrder<-ddply(Flanker_data, c("ID"), summarise,
Bad = identical(Flanker_TrialOrderTestVector, PreGoLabel))
write.csv(Flanker_BadTrialOrder, file = "Flanker_BadTrialOrder.csv") #save
summary(Flanker_BadTrialOrder)
#load the required packages:
library(reshape2)
library(plyr)
#Read in the example "Bad order" blocks for each task:
Flanker_block <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/CogBattery_UQ&Monash/Flanker_(B)_Expt.csv")
Cueing_block <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/CogBattery_UQ&Monash/Cueing_(D)_Expt.csv")
StopSignal_block1 <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/CogBattery_UQ&Monash/StopSignal_(D)_Expt1.csv")
StopSignal_block2 <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/CogBattery_UQ&Monash/StopSignal_(E)_Expt2.csv")
Comp_block <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/CogBattery_UQ&Monash/Comp_(D)_Expt.csv")
#Combine StopSignal_block1 and StopSignal_block2
StopSignal_block <- rbind(StopSignal_block1, StopSignal_block2)
#Read in the actual data for each task:
Comp_data <-read.csv("S:/R-MNHS-SPP/Bellgrove-data/CogBattery_UQ&Monash/AllParticipantData_comp.csv", header=T)
Flanker_data <-read.csv("S:/R-MNHS-SPP/Bellgrove-data/CogBattery_UQ&Monash/AllParticipantData_flanker.csv", header=T)
Cueing_data <-read.csv("S:/R-MNHS-SPP/Bellgrove-data/CogBattery_UQ&Monash/AllParticipantData_cueing.csv", header=T)
StopSignal_data <-read.csv("S:/R-MNHS-SPP/Bellgrove-data/CogBattery_UQ&Monash/AllParticipantData_StopSignal.csv", header=T)
#Remove rows with missing values
Comp_data<-Comp_data[Comp_data$TargetLoc!="",]
Flanker_data<-Flanker_data[Flanker_data$PreGoLabel!="",]
Cueing_data<-Cueing_data[Cueing_data$TargetName!="",]
StopSignal_data<-StopSignal_data[StopSignal_data$PreGoLabel!="",]
#Make the required factors:
Comp_data$TargetLoc <- factor(Comp_data$TargetLoc)
Cueing_data$TargetName <- factor(Cueing_data$TargetName)
StopSignal_data$PreGoLabel <- factor(StopSignal_data$PreGoLabel)
Flanker_data$PreGoLabel <- factor(Flanker_data$PreGoLabel)
#Set up the bad trial order test vectors for each block:
Comp_TrialOrderTestVector<-Comp_data$TargetLoc[Comp_data$ID=="507"]
Comp_TrialOrderTestVector2 <- factor(Comp_block$TargetLoc)
identical(Comp_TrialOrderTestVector,Comp_TrialOrderTestVector2)#just out of interest, test if these are identicle to the bad-trial-order hayley sent
#...its not. Anyway, it doesn't matter because I just used Participant 507 to get the bad-trial-order for the comp task anyway.
Flanker_TrialOrderTestVector <- factor(Flanker_block$PreGoLabel) #Hayley didn't tell me a participant with bad trial order
Cueing_TrialOrderTestVector <- Cueing_data$TargetName[Cueing_data$ID=="507"]
Cueing_TrialOrderTestVector2 <- factor(Cueing_block$TargetName)
identical(Cueing_TrialOrderTestVector,Cueing_TrialOrderTestVector2) #just out of interest, test if these are identicle to the bad-trial-order hayley sent
#...it is!
StopSignal_TrialOrderTestVector <- StopSignal_data$PreGoLabel[StopSignal_data$ID=="507"]
StopSignal_TrialOrderTestVector2 <- factor(StopSignal_block$PreGoLabel)
identical(StopSignal_TrialOrderTestVector,StopSignal_TrialOrderTestVector2) #just out of interest, test if these are identicle
#...it is!
#Check to make sure the data have all the same factor levels as TrialOrderTestVectors (and no extra levels)
summary(Comp_data$TargetLoc[Comp_data$ID=="1"])
summary(Comp_TrialOrderTestVector)
summary(Cueing_data$TargetName[Cueing_data$ID=="1"])
summary(Cueing_TrialOrderTestVector)
summary(Flanker_data$PreGoLabel[Flanker_data$ID=="1"])
summary(Flanker_TrialOrderTestVector)
summary(StopSignal_data$PreGoLabel[StopSignal_data$ID=="1"])
summary(StopSignal_TrialOrderTestVector)
summary(Comp_TrialOrderTestVector)
summary(Cueing_TrialOrderTestVector)
summary(Flanker_TrialOrderTestVector)
summary(StopSignal_TrialOrderTestVector)
Comp_data$allfactors<-interaction(Comp_data$SetSize, Comp_data$TargetHem, Comp_data$DisplayType)
summary(Comp_data$allfactors)
Comp_bad<-Comp_data$allfactors[Comp_data$ID=="507"]
summary(Comp_data$Comp_bad)
Comp_bad<-Comp_data$allfactors[Comp_data$ID=="507"]
summary(Comp_bad)
15914+9100
54+11
17610+49309+10000
76919/3
61925/3
# setwd(("C:/GitHub/BlueEnrichedLightRepo/Analyses Scripts_R"))
# stewd(("C:/GitHub/BlueEnrichedLightRepo/Analyses Scripts_R"))
stewd(("C:/GitHub/BlueEnrichedLightRepo/Analyses Scripts_R"))
(411.7164 + 373.0051)/2
3,422.58+1000
3422.58+1000
3422.58+$930
3422.58+930
16.8/.37
.168/.37
.37/.168
.335/.168
.34/.168
4352.58*2
190000*.1
500000*.16
25*65
26*1
12000*.165
12000*.17
1980-2040
839*2.39
48*12
2000/2.55
800*2.55
800*2.55
####Which computer/directory is this being run on?
location<-"Monash"
# location<-"DansLaptop"
if (location=="Monash") {
setwd(("C:/GitHub/ADHDvsControls/Analyses Scripts_R"))
} else if (location=="DansLaptop") {
setwd(("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_R"))
} else setwd(("~"))
####################################
#######  How to use ################
####################################
# 1) Install the packages and software specified below. (consider also updating all installed packages by chosing Update on the Packages tab)
# 2) Set the working directory (setwd) above, and directory where you have "data_ParticipantLevel", "master_matrix_R" and "ID_vector" saved
# 3) Hit Knit Word (or Knit HTML)! (Output can take while due to bootstrapping the robust effect size and calculating the Bayesian Highest Density Iinterval)
####################################
######  FIRST TIME ONLY ############
####################################
#Remove # in front of the line below and run the code. Replace the # after installing the packages, otherwise the R markdown script will give errors.
# install.packages(c("MASS", "akima", "robustbase", "cobs", "robust", "mgcv", "scatterplot3d", "quantreg", "rrcov", "lars", "pwr", "trimcluster", "mc2d", "psych", "Rfit","MBESS", "BayesFactor", "PoweR", "ggplot2", "reshape2", "plyr", "devtools", "rmarkdown","gmodels", "HLMdiag", "car", "gridExtra", "bootES", "BEST","foreign","nlme","pastecs","multcomp","ggplot2","compute.es","ez","lattice","lme4","effects","diagram","png", "grid"))
#Installation of the robust statistics package: Remove # in front of each of 4 lines below and run the code. Replace the # after installing the packages, otherwise the R markdown script will give errors.
# install.packages("devtools")
# library("devtools")
# install_github("mrxiaohe/WRScpp")
# install_github("nicebread/WRS", subdir="pkg")
#Download and install JAGS to calculate Bayesian HDI: http://sourceforge.net/projects/mcmc-jags/
###################################################################################################################################
## Install relevant libraries
library(foreign)
library(car)
library(nlme)
library(ggplot2)
library(pastecs)
library(psych)
library(plyr)
library(multcomp)
library(reshape2)
library(compute.es)
library(ez)
library(lattice)
library(lme4)
library(png)
library(grid)
###### Import single trial data:
if (location=="Monash") {
data <- read.csv("C:/GitHub/ADHDvsControls/Analyses Scripts_Matlab/master_matrix_R.csv", header=FALSE)
} else if (location=="DansLaptop") {
data <- read.csv("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_Matlab/master_matrix_R.csv", header=FALSE)
} else setwd(("~"))
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/ADHDvsControls/Analyses Scripts_Matlab/ID_vector.csv", quote="\"")
} else if (location=="DansLaptop") {
ID <- read.table("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_Matlab/ID_vector.csv", quote="\"")
} else setwd(("~"))
data$ID<-data[,1]
#Replace the participant numbers with IDs:
data[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data<-data[,!(names(data) %in% drops)]
###### Import data_ParticipantLevel:
if (location=="Monash") {
data_participant_level <- read.csv("C:/GitHub/ADHDvsControls/Analyses Scripts_Matlab/participant_level_matrix.csv", header=FALSE)
} else if (location=="DansLaptop") {
data_participant_level <- read.csv("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_Matlab/participant_level_matrix.csv", header=FALSE)
} else setwd(("~"))
#remove the RT measures that were calculated from ERP script - better to extract/colapse RT from the single-trial data_participant_level
data_participant_level<-data_participant_level[,-c(1:4)]
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/ADHDvsControls/Analyses Scripts_Matlab/IDs.csv", quote="\"")
} else if (location=="DansLaptop") {
ID <- read.csv("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_Matlab/IDs.csv", header=F)
} else setwd(("~"))
ID<-rename(ID,c("V1"="ID"))
data_participant_level$ID<-ID$ID
rm(ID)
# drops <- c("ID")
# data_participant_level<-data_participant_level[,!(names(data_participant_level) %in% drops)]
#import demographic data
if (location=="Monash") {
Demographics<-read.csv("C:/GitHub/ADHDvsControls/Analyses Scripts_R/ADHD_Control_Demographics_etc.csv", header=T)
} else if (location=="DansLaptop") {
Demographics<-read.csv("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_R/ADHD_Control_Demographics_etc.csv", header=T)
} else setwd(("~"))
#Merge Demographics into data_participant_level:
data_participant_level <- merge(data_participant_level, Demographics, by.x = "ID", by.y = "ID")
rm(Demographics)
#Rename data columns:
data<-rename(data, c("V1"="ID", "V2"="Group","V3"="TotalTrialNumber","V4"="Trial","V5"="ITI",
"V6"="Hemifield","V7"="Accuracy","V8"="RT",
"V9"="Blinkneg500to0","V10"="Blinkneg100_100PR","V11"="Blinkneg100_450",
"V12"="LeftFixBreakneg500_0","V13"="LeftFixBreakneg100_100PR","V14"="LeftFixBreakneg100_450",
"V15"="RightFixBreakneg500_0","V16"="RightFixBreakneg100_100PR","V17"="RightFixBreakneg100_450",
"V18"="BothFixBreakneg500_0","V19"="BothFixBreakneg100_100PR","V20"="BothFixBreakneg100_450",
"V21"="Art_neg500_0","V22"="Art_neg100_100PR","V23"="BLANK",
"V24"="RejectedTrial","V25"="Art_neg100_450","V26"="PreAlphaPowerLH",
"V27"="PreAlphaPowerRH","V28"="PreAlphaAsym","V29"="PrePupilDiameter", "V30"="N2c_GA","V31"="N2i_GA",
"V32"="RespLockedCPPSlope","V33"="StimLockedCPPSlope", "V34"="N2cPeakLatency", "V35"="CPPHalfPeakLatency",
"V36"="N2c_PA","V37"="N2i_PA"))   #NOTE: FOR N2c/i, the "_GA" or "_PA" suffix indicates whether N2c/i is measured with a measurement window based                                                        #on Grand average (GA) peak N2c/i latency, or based on Participant level average (PA) peak N2c/i latency
#Make the required columns into factors:
data$Group <- factor(data$Group)
data$ITI <- factor(data$ITI)
data$Hemifield <- factor(data$Hemifield)
# data$Sex <- factor(data$Sex)
data$Accuracy <- factor(data$Accuracy)
#Rename factor Levels:
data$Group <- revalue(data$Group, c("1"="ADHD", "2"="Control"))
data$ITI <- revalue(data$ITI, c("1"="3060ms", "2"="5170ms", "3"="7290ms"))
data$Hemifield <- revalue(data$Hemifield, c("1"="Left", "2"="Right"))
# data$Sex <- revalue(data$Sex, c("1"="Male", "2"="Female"))
data$Accuracy <- revalue(data$Accuracy, c("1"="Hit", "0"="Miss"))
#Re-class required vectors into Logicals:
data$Blinkneg500to0<-as.logical(data$Blinkneg500to0)
data$Blinkneg100_100PR<-as.logical(data$Blinkneg100_100PR)
data$Blinkneg100_450<-as.logical(data$Blinkneg100_450)
data$LeftFixBreakneg500_0<-as.logical(data$LeftFixBreakneg500_0)
data$LeftFixBreakneg100_100PR<-as.logical(data$LeftFixBreakneg100_100PR)
data$LeftFixBreakneg100_450<-as.logical(data$LeftFixBreakneg100_450)
data$RightFixBreakneg500_0<-as.logical(data$RightFixBreakneg500_0)
data$RightFixBreakneg100_100PR<-as.logical(data$RightFixBreakneg100_100PR)
data$RightFixBreakneg100_450<-as.logical(data$RightFixBreakneg100_450)
data$BothFixBreakneg500_0<-as.logical(data$BothFixBreakneg500_0)
data$BothFixBreakneg100_100PR<-as.logical(data$BothFixBreakneg100_100PR)
data$BothFixBreakneg100_100PR<-as.logical(data$BothFixBreakneg100_100PR)
data$BothFixBreakneg100_450<-as.logical(data$BothFixBreakneg100_450)
data$Art_neg500_0<-as.logical(data$Art_neg500_0)
data$Art_neg100_100PR<-as.logical(data$Art_neg100_100PR)
data$Art_neg100_450<-as.logical(data$Art_neg100_450)
data$RejectedTrial<-as.logical(data$RejectedTrial)
#Order any ordinal factors (may have to do this the "trail" or later too)
# by defult R uses polynomial contrasts for ordered factors, I'd rather treat light as unordered and to "treatment" contrasts, i.e. Low vs Med, Low vs High
data$ITI <- ordered(data$ITI, levels = c("3060ms", "5170ms", "7290ms"))
# data$Trial <- ordered(data$Trial)
###############Data Cleaning For Single Trial Data######################
#Check number of Trials for each participant by running the function 'length',
#on "data$RT" for each group, broken down by ID + Light
num_trials1 <- ddply(data, c("ID"), summarise,
Trials    = length(RT))
mean(num_trials1$Trials)
Accuracy_checker <- ddply(data, c("ID"), summarise,
Hits  = sum(Accuracy=="Hit"),
Misses = sum(Accuracy=="Miss"))
Accuracy_checker$Total=Accuracy_checker$Hits+Accuracy_checker$Misses
Accuracy_checker$Accuracy=(Accuracy_checker$Hits/Accuracy_checker$Total)*100
summary(Accuracy_checker$Accuracy)
#Remove rejected trials with trigger conflicts
data<-data[!data$RejectedTrial,]
#Remove trials where RT=0 (i.e. they did not respond)
data<-data[data$RT!=0,]
#Remove trials where RT longer than 1000ms (i.e. after target finished)
data<-data[data$RT<2000,]
#Remove trials where RT faster than 100ms (i.e. too fast must be false alarm)
data<-data[data$RT>200,]
#Remove trials with missing values :
data<-data[complete.cases(data),]
############################################ Log transform:
#################################################################################################################################
data$log_RT<-log(data$RT) #log
#####Z-score each participant's log_RT data ####
#calculate mean and sd
m <- tapply(data$log_RT,data$ID,mean)
s <- sqrt(tapply(data$log_RT,data$ID,var))
#calculate log_RT.Z and save it inside data.frame
data$log_RT.Z <- (data$log_RT-m[data$ID])/s[data$ID]
#check that Z scores have mean=0 and std=1
log_RT.Z_checker <- ddply(data, c("ID"), summarise,
N    = length(log_RT.Z ),
mean = round(mean(log_RT.Z )),
sd   = sd(log_RT.Z ),
se   = sd / sqrt(N))
summary(log_RT.Z_checker$mean)
#Remove trials where absolute log_RT.Z>3 (i.e. remove outlier RTs)
data<-data[!abs(data$log_RT.Z)>3,]
#plot again after outlier removal:
ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
hist_RT <- ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
hist_RT + facet_wrap(~ ID)
#Make PostAlpha contralateral (PostAlpha_c) and -Ipsilateral (PostAlpha_i) variables:
A<-data$Hemifield=="Left"
data$PostAlpha_c[A]<-data$RightHemi_PostAlpha[A]
data$PostAlpha_c[!A]<-data$LeftHemi_PostAlpha[!A]
data$PostAlpha_i[!A]<-data$LeftHemi_PostAlpha[!A]##################### MATLAB script doesn't extract this yet!!!
data$PostAlpha_i[A]<-data$RightHemi_PostAlpha[A]
rm(A)
#################################################################################################################################
#################################################################################################################################
#################################################################################################################################
#################################################################################################################################
#Rename data_participant_level columns of data_participant_level:
data_participant_level<-rename(data_participant_level, c("V5"="ValidPreAlphaTrials",
"V6"="ValidN2TrialsTrials","V7"="ValidCPPTrials","V8"="PreAlpha_LeftHemi",
"V9"="PreAlpha_RightHemi","V10"="N2c_LeftTarget_GA","V11"="N2c_RightTarget_GA",
"V12"="N2i_LeftTarget_GA","V13"="N2i_RightTarget_GA","V14"="AlphaDesync_LeftHemi_LeftTarget",
"V15"="AlphaDesync_LeftHemi_RightTarget","V16"="AlphaDesync_RightHemi_LeftTarget",
"V17"="AlphaDesync_RightHemi_RightTarget",
"V18"="CPPonset_LeftTarget","V19"="CPPonset_RightTarget","V20"="N2c_latency_LeftTarget",
"V21"="N2c_latency_RightTarget","V22"="N2i_latency_LeftTarget","V23"="N2i_latency_RightTarget",
"V24"="CPPslope_LeftTarget","V25"="CPPslope_RightTarget","V26"="FrontalNeg_slope_LeftTarget",
"V27"="FrontalNeg_slope_RightTarget", "V28"="ADHD_Control",
"V29"="N2c_LeftTarget_PA","V30"="N2c_RightTarget_PA",
"V31"="N2i_LeftTarget_PA","V32"="N2i_RightTarget_PA"))
#NOTE: FOR N2c/i, the "_GA" or "_PA" suffix indicates whether N2c/i is measured with a measurement window based                                                        #on Grand average (GA) peak N2c/i latency, or based on Participant level average (PA) peak N2c/i latency
write.csv(data_participant_level, file = "participant_level_data.csv", row.names = F)
#Look at Column names:
colnames(data_participant_level)
#Make the required columns into factors:
data_participant_level$Group <- factor(data_participant_level$Group)
#Rename factor Levels:
data_participant_level$Group <- revalue(data_participant_level$Group, c("1"="ADHD", "2"="Control"))
###Re-class required vectors into Logicals:
#data_participant_level$Blinkneg500to0<-as.logical(data_participant_level$Blinkneg500to0)
#Exclude the following participants from the ADHD group due to clinical cuttoff filter_CPRS_N_B
# AD69C', 'AD59C', 'AD27C', 'AD51C', 'AD98C'
#Exclude the following control participants:
#'C14', 'C259' for filter_CPRS_N_B; %C194 not enough valid trials
#Single trial
toBeRemoved<-which(data$ID=="AD69C" | data$ID=="AD59C" | data$ID=="AD27C" | data$ID=="AD51C" | data$ID=="AD98C" | data$ID=="C14" | data$ID=="C259"|  data$ID=="C194")
if (any(toBeRemoved)) {
data<-data[-toBeRemoved,]
}
#Participant level
toBeRemoved<-which(data_participant_level$ID=="AD69C" | data_participant_level$ID=="AD59C" | data_participant_level$ID=="AD27C" | data_participant_level$ID=="AD51C" | data_participant_level$ID=="AD98C" | data_participant_level$ID=="C14" | data_participant_level$ID=="C259"|  data_participant_level$ID=="C194")
if (any(toBeRemoved)) {
data_participant_level<-data_participant_level[-toBeRemoved,]
}
AlphaDesync_participant_level_long <- melt(data_participant_level, id.vars=c("ID", "Gender", "Group", "Age_B", "DAT1_3_Group"),
measure.vars=c("AlphaDesync_RightHemi_LeftTarget", "AlphaDesync_LeftHemi_RightTarget", "AlphaDesync_LeftHemi_LeftTarget", "AlphaDesync_RightHemi_RightTarget" ),
variable.name="Hemifield_by_Hemisphere",
value.name="AlphaDesync")
#Create seperate target Hemifield and Hemisphere factors
AlphaDesync_participant_level_long$Hemifield<-revalue(AlphaDesync_participant_level_long$Hemifield_by_Hemisphere, c("AlphaDesync_RightHemi_LeftTarget"="Left","AlphaDesync_LeftHemi_LeftTarget"="Left", "AlphaDesync_LeftHemi_RightTarget"="Right", "AlphaDesync_RightHemi_RightTarget"="Right"))
AlphaDesync_participant_level_long$Hemisphere<-revalue(AlphaDesync_participant_level_long$Hemifield_by_Hemisphere, c("AlphaDesync_RightHemi_LeftTarget"="Contralateral","AlphaDesync_LeftHemi_LeftTarget"="Ipsilateral", "AlphaDesync_LeftHemi_RightTarget"="Contralateral", "AlphaDesync_RightHemi_RightTarget"="Ipsilateral"))
#Histogram of participant's AlphaDesyncc scores by group and Hemifield
AlphaDesync_participant_level_long$Group_by_Hemifield_By_Hemisphere<-interaction(AlphaDesync_participant_level_long$Group,AlphaDesync_participant_level_long$Hemifield, AlphaDesync_participant_level_long$Hemisphere)
ggplot(AlphaDesync_participant_level_long, aes(AlphaDesync))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ Group_by_Hemifield_By_Hemisphere, ncol = 2)
#Find AlphaDesync Outliers
AlphaDesync_participant_level_long$AlphaDesync.Z<-scale(AlphaDesync_participant_level_long$AlphaDesync)
hist(AlphaDesync_participant_level_long$AlphaDesync.Z)
#Check which participants have outlier AlphaDesyncs
AlphaDesync_participant_level_long[!abs(AlphaDesync_participant_level_long$AlphaDesync.Z)<3,]
#Remove AlphaDesyncs Outliers
AlphaDesync_participant_level_long<-AlphaDesync_participant_level_long[abs(AlphaDesync_participant_level_long$AlphaDesync.Z)<3,]
hist(AlphaDesync_participant_level_long$AlphaDesync)
AlphaDesync_Perm<-ezPerm(data = AlphaDesync_participant_level_long, dv = .(AlphaDesync), wid = .(ID),  between = .(Group), within = .(Hemifield, Hemisphere), perms = 1000)
#Make Hemisphere a factor:
DF<-data.frame(data$ID, data$ITI, data$Hemifield, data$N2c_PA,data$N2i_PA, data$Trial, data$Blinkneg100_450, data$LeftFixBreakneg100_450, data$RightFixBreakneg100_450, data$Art_neg100_450, data$BothFixBreakneg100_450, data$Group)
names(DF) <- c("ID",  "ITI",	"Hemifield","N2c_PA","N2i_PA","Trial","Blinkneg100_450",
"LeftFixBreakneg100_450", "RightFixBreakneg100_450", "Art_neg100_450", "BothFixBreakneg100_450", "Group")
DF$contralateral<-rep("contralateral",length(DF[,1]))
DF$ipsilateral<-rep("ipsilateral",length(DF[,1]))
DF_contralateral<-subset(DF, select=c(ID, ITI, Hemifield,N2c_PA,contralateral,Trial,Blinkneg100_450,
LeftFixBreakneg100_450, RightFixBreakneg100_450, Art_neg100_450, BothFixBreakneg100_450,Group))
DF_ipsilateral<-subset(DF, select=c(ID, ITI, Hemifield,N2i_PA,ipsilateral,Trial,Blinkneg100_450,
LeftFixBreakneg100_450, RightFixBreakneg100_450, Art_neg100_450, BothFixBreakneg100_450,Group))
names(DF_contralateral)[names(DF_contralateral)=="contralateral"] <- "Hemisphere"
names(DF_ipsilateral)[names(DF_ipsilateral)=="ipsilateral"] <- "Hemisphere"
names(DF_contralateral)[names(DF_contralateral)=="N2c_PA"] <- "N2"
names(DF_ipsilateral)[names(DF_ipsilateral)=="N2i_PA"] <- "N2"
DF<-rbind(DF_contralateral,DF_ipsilateral)
rm(DF_contralateral,DF_ipsilateral)
DF$Hemisphere <- factor(DF$Hemisphere)
DF<-DF[!DF$Blinkneg100_450 & !DF$LeftFixBreakneg100_450 & !DF$RightFixBreakneg100_450 & !DF$Art_neg100_450 & !DF$BothFixBreakneg100_450, ]
DF$IDbyHemifieldbyITIbyHemispherebyHemisphere<-interaction(DF$ID, DF$Hemifield, DF$ITI, DF$Hemisphere)
#calculate mean and sd
m <- tapply(DF$N2,DF$IDbyHemifieldbyITIbyHemisphere,mean)
s <- sqrt(tapply(DF$N2,DF$IDbyHemifieldbyITIbyHemisphere,var))
#calculate N2.Z and save it inside data.frame
DF$N2.Z <- (DF$N2-m[DF$IDbyHemifieldbyITIbyHemisphere])/s[DF$IDbyHemifieldbyITIbyHemisphere]
#check that Z scores have mean=0 and std=1
N2.Z_checker <- ddply(DF, c("ID", "Hemifield", "ITI", "Hemisphere"), summarise,
N    = length(N2.Z ),
mean = round(mean(N2.Z )),
sd   = sd(N2.Z ),
se   = sd / sqrt(N))
##Remove trials where absolute N2.Z>3 (i.e. remove outlier N2s)
DF<-DF[!abs(DF$N2.Z)>3,]
N2_random_intercepts_only<-lmer(N2 ~ 1 + (1 | ID/Hemisphere) +(1|ITI) + (1|Hemifield) + (1|Trial), data = DF, REML=FALSE, na.action = na.omit)
N2_Group<-update(N2_random_intercepts_only, .~. + Group)
N2_Hemifield<-update(N2_Group, .~. + Hemifield)
N2_Hemisphere<-update(N2_Hemifield, .~. + Hemisphere)
N2_HemifieldbyGroup<-update(N2_Hemisphere, .~. + Hemifield:Group)
N2_HemispherebyGroup<-update(N2_HemifieldbyGroup, .~. + Hemisphere:Group)
N2_HemifieldbyHemisphere<-update(N2_HemispherebyGroup, .~. + Hemisphere:Hemifield)
N2_HemifieldbyGroupbyHemisphere<-update(N2_HemifieldbyHemisphere, .~. + Hemifield:Group:Hemisphere)
anova(N2_random_intercepts_only, N2_Group, N2_Hemifield, N2_Hemisphere, N2_HemifieldbyGroup, N2_HemispherebyGroup, N2_HemifieldbyHemisphere, N2_HemifieldbyGroupbyHemisphere)
#Make Hemisphere a factor:
DF<-data.frame(data$ID, data$ITI, data$Hemifield, data$N2c_PA,data$N2i_PA, data$Trial, data$Blinkneg100_450, data$LeftFixBreakneg100_450, data$RightFixBreakneg100_450, data$Art_neg100_450, data$BothFixBreakneg100_450, data$Group)
names(DF) <- c("ID",  "ITI",	"Hemifield","N2c_PA","N2i_PA","Trial","Blinkneg100_450",
"LeftFixBreakneg100_450", "RightFixBreakneg100_450", "Art_neg100_450", "BothFixBreakneg100_450", "Group")
DF$contralateral<-rep("contralateral",length(DF[,1]))
DF$ipsilateral<-rep("ipsilateral",length(DF[,1]))
DF_contralateral<-subset(DF, select=c(ID, ITI, Hemifield,N2c_PA,contralateral,Trial,Blinkneg100_450,
LeftFixBreakneg100_450, RightFixBreakneg100_450, Art_neg100_450, BothFixBreakneg100_450,Group))
DF_ipsilateral<-subset(DF, select=c(ID, ITI, Hemifield,N2i_PA,ipsilateral,Trial,Blinkneg100_450,
LeftFixBreakneg100_450, RightFixBreakneg100_450, Art_neg100_450, BothFixBreakneg100_450,Group))
names(DF_contralateral)[names(DF_contralateral)=="contralateral"] <- "Hemisphere"
names(DF_ipsilateral)[names(DF_ipsilateral)=="ipsilateral"] <- "Hemisphere"
names(DF_contralateral)[names(DF_contralateral)=="N2c_PA"] <- "N2"
names(DF_ipsilateral)[names(DF_ipsilateral)=="N2i_PA"] <- "N2"
DF<-rbind(DF_contralateral,DF_ipsilateral)
rm(DF_contralateral,DF_ipsilateral)
DF$Hemisphere <- factor(DF$Hemisphere)
DF<-DF[!DF$Blinkneg100_450 & !DF$LeftFixBreakneg100_450 & !DF$RightFixBreakneg100_450 & !DF$Art_neg100_450 & !DF$BothFixBreakneg100_450, ]
DF$IDbyHemifieldbyITIbyHemispherebyHemisphere<-interaction(DF$ID, DF$Hemifield, DF$ITI, DF$Hemisphere)
#calculate mean and sd
m <- tapply(DF$N2,DF$IDbyHemifieldbyITIbyHemisphere,mean)
s <- sqrt(tapply(DF$N2,DF$IDbyHemifieldbyITIbyHemisphere,var))
#calculate N2.Z and save it inside data.frame
DF$N2.Z <- (DF$N2-m[DF$IDbyHemifieldbyITIbyHemisphere])/s[DF$IDbyHemifieldbyITIbyHemisphere]
#check that Z scores have mean=0 and std=1
N2.Z_checker <- ddply(DF, c("ID", "Hemifield", "ITI", "Hemisphere"), summarise,
N    = length(N2.Z ),
mean = round(mean(N2.Z )),
sd   = sd(N2.Z ),
se   = sd / sqrt(N))
##Remove trials where absolute N2.Z>3 (i.e. remove outlier N2s)
DF<-DF[!abs(DF$N2.Z)>3,]
## NO EFFECTS OF TOT on N2:
##Check for TOT effects:
N2_TOT<-update(N2_HemifieldbyGroupbyHemisphere, .~. + Trial)
N2_GroupbyTOT<-update(N2_TOT, .~. + Trial*Group)
N2_HemifieldbyTOT<-update(N2_GroupbyTOT, .~. + Trial*Hemifield)
N2_HemispherebyTOT<-update(N2_HemifieldbyTOT, .~. + Trial*Hemisphere)
N2_HemifieldbyGroupbyTOT<-update(N2_HemispherebyTOT, .~. + Trial*Hemifield*Group)
N2_HemispherebyGroupbyTOT<-update(N2_HemifieldbyGroupbyTOT, .~. + Trial*Hemisphere*Group)
N2_HemifieldbyHemispherebyTOT<-update(N2_HemispherebyGroupbyTOT, .~. + Trial*Hemisphere*Hemifield)
N2_HemifieldbyGroupbyHemispherebyTOT<-update(N2_HemifieldbyHemispherebyTOT, .~. + Trial*Hemisphere*Hemifield*Group)
anova(N2_HemifieldbyGroupbyHemisphere, N2_TOT, N2_GroupbyTOT, N2_HemifieldbyTOT,N2_HemispherebyTOT,N2_HemifieldbyGroupbyTOT,N2_HemispherebyGroupbyTOT,N2_HemifieldbyHemispherebyTOT,N2_HemifieldbyGroupbyHemispherebyTOT)
