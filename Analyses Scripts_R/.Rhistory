data<-data[complete.cases(data),]
## Remove outliers
data$RT_index.Z<-scale(data$RT_index)
data<-data[abs(data$RT_index.Z)<3,]
ez::ezANOVA(
data = data
, dv = .(RT_index)
, wid = .(ID)
, between = .(DAT1_3UTR)
, type = 3
, detailed = F
, between_covariates= .("Site")
)
DAT1 <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/DAT1genotypes_forR.csv", na.strings="")
RT_index <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/RT_index_forR.csv", na.strings="")
summary(DAT1)
summary(DAT1$DAT1_3UTR_VNTRraw)
#Make the required columns into factors:
DAT1$DAT1_3UTR_VNTRraw <- factor(DAT1$DAT1_3UTR_VNTRraw)
DAT1$Site <- factor(DAT1$Site)
DAT1$DAT1_10_10_repeats  <- plyr::revalue(DAT1$DAT1_3UTR_VNTRraw ,
c("10 10"="Two",
"10 11"="One",
"7 10"="One",
"7 9"="Zero",
"8 11"="Zero",
"9 10"="One",
"9 9"="Zero"))
summary(DAT1$DAT1_10_10_repeats)
DAT1$DAT1_3UTR  <- plyr::revalue(DAT1$DAT1_3UTR_VNTRraw ,
c("10 10"="10_10_repeat",
"10 11"="non10_10_repeat",
"7 10"="non10_10_repeat",
"7 9"="non10_10_repeat",
"8 11"="non10_10_repeat",
"9 10"="non10_10_repeat",
"9 9"="non10_10_repeat"))
summary(DAT1$DAT1_3UTR)
DAT1$DAT1_int8  <- plyr::revalue(DAT1$DAT1_Int8_VNTRraw ,
c("6 6"="6_6_repeat",
"5 6"="non6_6_repeat",
"5 5"="non6_6_repeat"))
summary(DAT1$DAT1_int8)
#### Merge the data sets together
data<-merge(DAT1, RT_index, c("ID"))
########### Overall leftward Bias?? ############
t.test (data$RT_index, mu=0)
## Remove outliers
data$RT_index.Z<-scale(data$RT_index)
data<-data[abs(data$RT_index.Z)<3,]
data<-data[complete.cases(data),]
data$RT_index.Z<-scale(data$RT_index)
data<-data[abs(data$RT_index.Z)<3,]
DAT1 <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/DAT1genotypes_forR.csv", na.strings="")
RT_index <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/RT_index_forR.csv", na.strings="")
summary(DAT1)
summary(DAT1$DAT1_3UTR_VNTRraw)
#Make the required columns into factors:
DAT1$DAT1_3UTR_VNTRraw <- factor(DAT1$DAT1_3UTR_VNTRraw)
DAT1$Site <- factor(DAT1$Site)
DAT1$DAT1_10_10_repeats  <- plyr::revalue(DAT1$DAT1_3UTR_VNTRraw ,
c("10 10"="Two",
"10 11"="One",
"7 10"="One",
"7 9"="Zero",
"8 11"="Zero",
"9 10"="One",
"9 9"="Zero"))
summary(DAT1$DAT1_10_10_repeats)
DAT1$DAT1_3UTR  <- plyr::revalue(DAT1$DAT1_3UTR_VNTRraw ,
c("10 10"="10_10_repeat",
"10 11"="non10_10_repeat",
"7 10"="non10_10_repeat",
"7 9"="non10_10_repeat",
"8 11"="non10_10_repeat",
"9 10"="non10_10_repeat",
"9 9"="non10_10_repeat"))
summary(DAT1$DAT1_3UTR)
DAT1$DAT1_int8  <- plyr::revalue(DAT1$DAT1_Int8_VNTRraw ,
c("6 6"="6_6_repeat",
"5 6"="non6_6_repeat",
"5 5"="non6_6_repeat"))
summary(DAT1$DAT1_int8)
#### Merge the data sets together
data<-merge(DAT1, RT_index, c("ID"))
########### Overall leftward Bias?? ############
t.test (data$RT_index, mu=0)
## Remove outliers
data$RT_index.Z<-scale(data$RT_index)
data<-data[abs(data$RT_index.Z)<3,]
##Remove those with missing genotypes
data<-data[complete.cases(data),]
View(data)
DAT1 <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/DAT1genotypes_forR.csv", na.strings="")
RT_index <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/RT_index_forR.csv", na.strings="")
summary(DAT1)
summary(DAT1$DAT1_3UTR_VNTRraw)
#Make the required columns into factors:
DAT1$DAT1_3UTR_VNTRraw <- factor(DAT1$DAT1_3UTR_VNTRraw)
DAT1$Site <- factor(DAT1$Site)
DAT1$DAT1_10_10_repeats  <- plyr::revalue(DAT1$DAT1_3UTR_VNTRraw ,
c("10 10"="Two",
"10 11"="One",
"7 10"="One",
"7 9"="Zero",
"8 11"="Zero",
"9 10"="One",
"9 9"="Zero"))
summary(DAT1$DAT1_10_10_repeats)
DAT1$DAT1_3UTR  <- plyr::revalue(DAT1$DAT1_3UTR_VNTRraw ,
c("10 10"="10_10_repeat",
"10 11"="non10_10_repeat",
"7 10"="non10_10_repeat",
"7 9"="non10_10_repeat",
"8 11"="non10_10_repeat",
"9 10"="non10_10_repeat",
"9 9"="non10_10_repeat"))
summary(DAT1$DAT1_3UTR)
DAT1$DAT1_int8  <- plyr::revalue(DAT1$DAT1_Int8_VNTRraw ,
c("6 6"="6_6_repeat",
"5 6"="non6_6_repeat",
"5 5"="non6_6_repeat"))
summary(DAT1$DAT1_int8)
#### Merge the data sets together
data<-merge(DAT1, RT_index, c("ID"))
########### Overall leftward Bias?? ############
t.test (data$RT_index, mu=0)
## Remove outliers
data$RT_index.Z<-scale(data$RT_index)
data<-data[abs(data$RT_index.Z)<3,]
data<-data[complete.cases(data),]
ggplot2::ggplot(data, aes(RT_index))  +
geom_histogram(aes(y=..count..), colour="black", fill="white") +
facet_wrap(~ DAT1_3UTR)
ggplot2::ggplot(data, aes(RT_index, colour = DAT1_3UTR))  +
geom_density(alpha = 0.1)
ez::ezANOVA(
data = data
, dv = .(RT_index)
, wid = .(ID)
, between = .(DAT1_3UTR)
, type = 3
, detailed = F
, between_covariates= .("Site")
)
ez::ezPerm(
data = data
, dv = .(RT_index)
, wid = .(ID)
, between = .(DAT1_3UTR)
)
boot<-ez::ezBoot(
data = data
, dv = .(RT_index)
, wid = .(ID)
, between = .(DAT1_3UTR)
)
ez::ezPlot2(boot, x=DAT1_3UTR, y_lab = "RT asymmetry index")
t.test (data$RT_index[data$DAT1_3UTR=="non10_10_repeat"], mu=0)
t.test (data$RT_index[data$DAT1_3UTR=="10_10_repeat"], mu=0)
ggplot2::ggplot(data, aes(scale(RT_index)))  +
geom_histogram(aes(y=..count..), colour="black", fill="white") +
facet_wrap(~ DAT1_3UTR)
ggplot2::ggplot(data, aes(RT_index, colour = DAT1_3UTR))  +
geom_density(alpha = 0.1)
ez::ezANOVA(
data = data
, dv = .(RT_index)
, wid = .(ID)
, between = .(DAT1_3UTR)
, type = 3
, detailed = F
, between_covariates= .("Site")
)
summary(DAT1$DAT1_3UTR)
summary(data$DAT1_3UTR)
View(data)
View(DAT1)
data$RT_overall<-mean(data$RT_left, RT_right)
data$RT_overall<-mean(data$RT_left, data$RT_right)
data$RT_overall<-mean(data$RT_left + data$RT_right)/2
ez::ezANOVA(
data = data
, dv = .(RT_overall)
, wid = .(ID)
, between = .(DAT1_3UTR)
, type = 3
, detailed = F
, between_covariates= .("Site")
)
? mean
data$RT_overall<(-mean(data$RT_left + data$RT_right)/2)
data$RT_overall<-(mean(data$RT_left + data$RT_right)/2)
data$RT_overall<-(rowMeans(data$RT_left + data$RT_right)/2)
rowMeans(data$RT_left + data$RT_right)/2
? rowMeans
data$RT_overall<-rowMeans(data$RT_left + data$RT_right)
data$RT_overall<-rowMeans(c(data$RT_left + data$RT_right))
apply(rbind(data$RT_left,data$RT_right),2,mean)
(467.9143+458.4892)/2
data$RT_overall<-apply(rbind(data$RT_left,data$RT_right),2,mean)
ez::ezANOVA(
data = data
, dv = .(RT_overall)
, wid = .(ID)
, between = .(DAT1_3UTR)
, type = 3
, detailed = F
, between_covariates= .("Site")
)
boot<-ez::ezBoot(
data = data
, dv = .(RT_overall)
, wid = .(ID)
, between = .(DAT1_3UTR)
)
ez::ezPlot2(boot, x=DAT1_3UTR)
d.f <- data.frame(rating = c("AAA", "A", "A", "AAA",
"BB", "BB", "AAA", "A"))
i <- 1
by <- d.f$rating
sub.data.frame <- d.f[by == unique(by)[i], ]
View(d.f)
values <- data.frame(value = c("a", "a", "a", "a", "a",
"b", "b", "b",
"c", "c", "c", "c"))
nr.of.appearances <- aggregate(x = values,
by = list(unique.values = values$value),
FUN = length)
View(values)
View(nr.of.appearances)
View(d.f)
DAT1 <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/DAT1genotypes_forR.csv", na.strings="")
RT_index <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/RT_index_forR.csv", na.strings="")
t.test(RT_index$RT_left,RT_index$RT_right, paired=TRUE)
mean(RT_index$RT_left)
#Std error.
sd(RT_index$RT_left) / sqrt(length(RT_index$RT_left))
mean(RT_index$RT_left)
#Std error.
sd(RT_index$RT_left) / sqrt(length(RT_index$RT_left))
#Mean right targets
mean(RT_index$RT_right)
#Std error.
sd(RT_index$RT_left) / sqrt(length(RT_index$RT_left))
751-585
571-585
mean(RT_index$RT_left)
hist(RT_index$RT_right)
hist(RT_index$RT_left)
hist(RT_index$RT_right)
hist(RT_index$RT_left)
hist(RT_index$RT_right)
hist(log(RT_index$RT_right))
hist(log(RT_index$RT_left))
t.test(log(RT_index$RT_left),log(RT_index$RT_right), paired=TRUE)
t.test(log(RT_index$RT_left),log(RT_index$RT_right), paired=TRUE)
t.test(log(RT_index$RT_left),log(RT_index$RT_right), paired=TRUE)
mean(RT_index$RT_left)
sd(RT_index$RT_left) / sqrt(length(RT_index$RT_left))
DAT1 <- read.csv("S:/R-MNHS-SPP/Bellgrove-data/4. Dan Newman/Participant Folders_new/DAT1genotypes_forR.csv", na.strings="")
mean(RT_index$RT_right)
mean(RT_index$RT_right)
sd(RT_index$RT_left) / sqrt(length(RT_index$RT_left))
sd(RT_index$RT_right) / sqrt(length(RT_index$RT_right))
####Which computer/directory is this being run on?
location<-"Monash"
# location<-"DansLaptop"
if (location=="Monash") {
setwd(("C:/GitHub/ADHDvsControls/Analyses Scripts_R"))
} else if (location=="DansLaptop") {
setwd(("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_R"))
} else setwd(("~"))
####################################
#######  How to use ################
####################################
# 1) Install the packages and software specified below. (consider also updating all installed packages by chosing Update on the Packages tab)
# 2) Set the working directory (setwd) above, and directory where you have "data_ParticipantLevel", "master_matrix_R" and "ID_vector" saved
# 3) Hit Knit Word (or Knit HTML)! (Output can take while due to bootstrapping the robust effect size and calculating the Bayesian Highest Density Iinterval)
####################################
######  FIRST TIME ONLY ############
####################################
#Remove # in front of the line below and run the code. Replace the # after installing the packages, otherwise the R markdown script will give errors.
# install.packages(c("MASS", "akima", "robustbase", "cobs", "robust", "mgcv", "scatterplot3d", "quantreg", "rrcov", "lars", "pwr", "trimcluster", "mc2d", "psych", "Rfit","MBESS", "BayesFactor", "PoweR", "ggplot2", "reshape2", "plyr", "devtools", "rmarkdown","gmodels", "HLMdiag", "car", "gridExtra", "bootES", "BEST","foreign","nlme","pastecs","multcomp","ggplot2","compute.es","ez","lattice","lme4","effects","diagram","png", "grid", "dplyr"))
#Installation of the robust statistics package: Remove # in front of each of 4 lines below and run the code. Replace the # after installing the packages, otherwise the R markdown script will give errors.
# install.packages("devtools")
# library("devtools")
# install_github("mrxiaohe/WRScpp")
# install_github("nicebread/WRS", subdir="pkg")
#Download and install JAGS to calculate Bayesian HDI: http://sourceforge.net/projects/mcmc-jags/
###################################################################################################################################
## Install relevant libraries
library(foreign)
library(car)
library(nlme)
library(ggplot2)
library(pastecs)
library(psych)
library(plyr)
library(multcomp)
library(reshape2)
library(compute.es)
library(ez)
library(lattice)
library(lme4)
library(png)
library(grid)
###### Import single trial data:
if (location=="Monash") {
data <- read.csv("C:/GitHub/ADHDvsControls/Analyses Scripts_Matlab/master_matrix_R.csv", header=FALSE)
} else if (location=="DansLaptop") {
data <- read.csv("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_Matlab/master_matrix_R.csv", header=FALSE)
} else setwd(("~"))
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/ADHDvsControls/Analyses Scripts_Matlab/ID_vector.csv", quote="\"")
} else if (location=="DansLaptop") {
ID <- read.table("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_Matlab/ID_vector.csv", quote="\"")
} else setwd(("~"))
data$ID<-data[,1]
#Replace the participant numbers with IDs:
data[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data<-data[,!(names(data) %in% drops)]
###### Import data_ParticipantLevel:
if (location=="Monash") {
data_participant_level <- read.csv("C:/GitHub/ADHDvsControls/Analyses Scripts_Matlab/participant_level_matrix.csv", header=FALSE)
} else if (location=="DansLaptop") {
data_participant_level <- read.csv("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_Matlab/participant_level_matrix.csv", header=FALSE)
} else setwd(("~"))
#remove the RT measures that were calculated from ERP script - better to extract/colapse RT from the single-trial data_participant_level
data_participant_level<-data_participant_level[,-c(1:4)]
#Import IDs:
if (location=="Monash") {
ID <- read.table("C:/GitHub/ADHDvsControls/Analyses Scripts_Matlab/IDs.csv", quote="\"")
} else if (location=="DansLaptop") {
ID <- read.csv("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_Matlab/IDs.csv", header=F)
} else setwd(("~"))
ID<-plyr::rename(ID,c("V1"="ID"))
data_participant_level$ID<-ID$ID
rm(ID)
# drops <- c("ID")
# data_participant_level<-data_participant_level[,!(names(data_participant_level) %in% drops)]
#import demographic data
if (location=="Monash") {
Demographics<-read.csv("C:/GitHub/ADHDvsControls/Analyses Scripts_R/ADHD_Control_Demographics_etc.csv", header=T)
} else if (location=="DansLaptop") {
Demographics<-read.csv("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_R/ADHD_Control_Demographics_etc.csv", header=T)
} else setwd(("~"))
#Merge Demographics into data_participant_level:
data_participant_level <- merge(data_participant_level, Demographics, by.x = "ID", by.y = "ID")
rm(Demographics)
#Rename data columns:
data<-rename(data, c("V1"="ID", "V2"="Group","V3"="TotalTrialNumber","V4"="Trial","V5"="ITI",
"V6"="Hemifield","V7"="Accuracy","V8"="RT",
"V9"="Blinkneg500to0","V10"="Blinkneg100_100PR","V11"="Blinkneg100_450",
"V12"="LeftFixBreakneg500_0","V13"="LeftFixBreakneg100_100PR","V14"="LeftFixBreakneg100_450",
"V15"="RightFixBreakneg500_0","V16"="RightFixBreakneg100_100PR","V17"="RightFixBreakneg100_450",
"V18"="BothFixBreakneg500_0","V19"="BothFixBreakneg100_100PR","V20"="BothFixBreakneg100_450",
"V21"="Art_neg500_0","V22"="Art_neg100_100PR","V23"="BLANK",
"V24"="RejectedTrial","V25"="Art_neg100_450","V26"="PreAlphaPowerLH",
"V27"="PreAlphaPowerRH","V28"="PreAlphaAsym","V29"="PrePupilDiameter", "V30"="N2c_GA","V31"="N2i_GA",
"V32"="RespLockedCPPSlope","V33"="StimLockedCPPSlope", "V34"="N2cPeakLatency", "V35"="CPPHalfPeakLatency",
"V36"="N2c_PA","V37"="N2i_PA"))
#NOTE: FOR N2c/i,  the _GA or _PA suffix indicates whether N2c/i is measured with a measurement window based
#on Grand average (GA) peak N2c/i latency,  or based on Participant level average (PA) peak N2c/i latency
#Make the required columns into factors:
data$Group <- factor(data$Group)
data$ITI <- factor(data$ITI)
data$Hemifield <- factor(data$Hemifield)
# data$Sex <- factor(data$Sex)
data$Accuracy <- factor(data$Accuracy)
#Rename factor Levels:
data$Group <- revalue(data$Group, c("1"="ADHD", "2"="Control"))
data$ITI <- revalue(data$ITI, c("1"="3060ms", "2"="5170ms", "3"="7290ms"))
data$Hemifield <- revalue(data$Hemifield, c("1"="Left", "2"="Right"))
# data$Sex <- revalue(data$Sex, c("1"="Male", "2"="Female"))
data$Accuracy <- revalue(data$Accuracy, c("1"="Hit", "0"="Miss"))
#Re-class required vectors into Logicals:
data$Blinkneg500to0<-as.logical(data$Blinkneg500to0)
data$Blinkneg100_100PR<-as.logical(data$Blinkneg100_100PR)
data$Blinkneg100_450<-as.logical(data$Blinkneg100_450)
data$LeftFixBreakneg500_0<-as.logical(data$LeftFixBreakneg500_0)
data$LeftFixBreakneg100_100PR<-as.logical(data$LeftFixBreakneg100_100PR)
data$LeftFixBreakneg100_450<-as.logical(data$LeftFixBreakneg100_450)
data$RightFixBreakneg500_0<-as.logical(data$RightFixBreakneg500_0)
data$RightFixBreakneg100_100PR<-as.logical(data$RightFixBreakneg100_100PR)
data$RightFixBreakneg100_450<-as.logical(data$RightFixBreakneg100_450)
data$BothFixBreakneg500_0<-as.logical(data$BothFixBreakneg500_0)
data$BothFixBreakneg100_100PR<-as.logical(data$BothFixBreakneg100_100PR)
data$BothFixBreakneg100_100PR<-as.logical(data$BothFixBreakneg100_100PR)
data$BothFixBreakneg100_450<-as.logical(data$BothFixBreakneg100_450)
data$Art_neg500_0<-as.logical(data$Art_neg500_0)
data$Art_neg100_100PR<-as.logical(data$Art_neg100_100PR)
data$Art_neg100_450<-as.logical(data$Art_neg100_450)
data$RejectedTrial<-as.logical(data$RejectedTrial)
#Order any ordinal factors (may have to do this the "trail" or later too)
# by defult R uses polynomial contrasts for ordered factors, I'd rather treat light as unordered and to "treatment" contrasts, i.e. Low vs Med, Low vs High
data$ITI <- ordered(data$ITI, levels = c("3060ms", "5170ms", "7290ms"))
# data$Trial <- ordered(data$Trial)
###############Data Cleaning For Single Trial Data######################
#Check number of Trials for each participant by running the function 'length',
#on "data$RT" for each group, broken down by ID + Light
num_trials1 <- ddply(data, c("ID"), summarise,
Trials    = length(RT))
mean(num_trials1$Trials)
Accuracy_checker <- ddply(data, c("ID"), summarise,
Hits  = sum(Accuracy=="Hit"),
Misses = sum(Accuracy=="Miss"))
Accuracy_checker$Total=Accuracy_checker$Hits+Accuracy_checker$Misses
Accuracy_checker$Accuracy=(Accuracy_checker$Hits/Accuracy_checker$Total)*100
summary(Accuracy_checker$Accuracy)
#Remove rejected trials with trigger conflicts
data<-data[!data$RejectedTrial,]
#Remove trials where RT=0 (i.e. they did not respond)
data<-data[data$RT!=0,]
#Remove trials where RT longer than 1000ms (i.e. after target finished)
data<-data[data$RT<2000,]
#Remove trials where RT faster than 100ms (i.e. too fast must be false alarm)
data<-data[data$RT>200,]
#Remove trials with missing values :
data<-data[complete.cases(data),]
############################################ Log transform:
#################################################################################################################################
data$log_RT<-log(data$RT) #log
data$sqrt_RT<-sqrt(data$RT)
ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ Group)
ggplot(data, aes(log_RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ Group)
ggplot(data, aes(sqrt_RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ Group)
ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ ID)
#####Z-score each participant's log_RT data ####
#calculate mean and sd
m <- tapply(data$log_RT,data$ID,mean)
s <- sqrt(tapply(data$log_RT,data$ID,var))
#calculate log_RT.Z and save it inside data.frame
data$log_RT.Z <- (data$log_RT-m[data$ID])/s[data$ID]
#check that Z scores have mean=0 and std=1
log_RT.Z_checker <- ddply(data, c("ID"), summarise,
N    = length(log_RT.Z ),
mean = round(mean(log_RT.Z )),
sd   = sd(log_RT.Z ),
se   = sd / sqrt(N))
summary(log_RT.Z_checker$mean)
summary(log_RT.Z_checker$sd)
#Remove trials where absolute log_RT.Z>3 (i.e. remove outlier RTs)
data<-data[!abs(data$log_RT.Z)>3,]
#plot again after outlier removal:
ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ Group)
ggplot(data, aes(log_RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ Group)
ggplot(data, aes(sqrt_RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ Group)
ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white") + facet_wrap(~ ID)
#Make PostAlpha contralateral (PostAlpha_c) and -Ipsilateral (PostAlpha_i) variables:
# A<-data$Hemifield=="Left"
# data$PostAlpha_c[A]<-data$RightHemi_PostAlpha[A]
# data$PostAlpha_c[!A]<-data$LeftHemi_PostAlpha[!A]
# data$PostAlpha_i[!A]<-data$LeftHemi_PostAlpha[!A]##################### MATLAB script doesn't extract this yet!!!
# data$PostAlpha_i[A]<-data$RightHemi_PostAlpha[A]
# rm(A)
#################################################################################################################################
#################################################################################################################################
#################################################################################################################################
#################################################################################################################################
#Rename data_participant_level columns of data_participant_level:
data_participant_level<-rename(data_participant_level, c("V5"="ValidPreAlphaTrials",
"V6"="ValidN2TrialsTrials","V7"="ValidCPPTrials","V8"="PreAlpha_LeftHemi",
"V9"="PreAlpha_RightHemi","V10"="N2c_LeftTarget_GA","V11"="N2c_RightTarget_GA",
"V12"="N2i_LeftTarget_GA","V13"="N2i_RightTarget_GA","V14"="AlphaDesync_LeftHemi_LeftTarget",
"V15"="AlphaDesync_LeftHemi_RightTarget","V16"="AlphaDesync_RightHemi_LeftTarget",
"V17"="AlphaDesync_RightHemi_RightTarget",
"V18"="CPPonset_LeftTarget","V19"="CPPonset_RightTarget","V20"="N2c_latency_LeftTarget",
"V21"="N2c_latency_RightTarget","V22"="N2i_latency_LeftTarget","V23"="N2i_latency_RightTarget",
"V24"="CPPslope_LeftTarget","V25"="CPPslope_RightTarget","V26"="FrontalNeg_slope_LeftTarget",
"V27"="FrontalNeg_slope_RightTarget", "V28"="ADHD_Control",
"V29"="N2c_LeftTarget_PA","V30"="N2c_RightTarget_PA",
"V31"="N2i_LeftTarget_PA","V32"="N2i_RightTarget_PA"))
#NOTE: FOR N2c/i ,  the _GA or _PA suffix indicates whether N2c/i is measured with a measurement window based
#on Grand average (GA) peak N2c/i latency ,  or based on Participant level average (PA) peak N2c/i latency
write.csv(data_participant_level, file = "participant_level_data.csv", row.names = F)
#Look at Column names:
colnames(data_participant_level)
#Make the required columns into factors:
data_participant_level$Group <- factor(data_participant_level$Group)
#Rename factor Levels:
data_participant_level$Group <- revalue(data_participant_level$Group, c("1"="ADHD", "2"="Control"))
library(dplyr)
data_participant_level <- dplyr::filter(data_participant_level,
ValidCPPTrials > 50 & ((Group=="ADHD" & CPRS_N_B >= 65) | (Group=="Control" & CPRS_N_B <= 60)))
dplyr::filter(data, ID2 %in% target)
target<-as.character(data_participant_level$ID)
data$ID2<-as.character(data$ID)
dplyr::filter(data, ID2 %in% target)
library(dplyr)
dplyr::filter(data, ID2 %in% target)
dplyr::filter_(data, ID2 %in% target)
target<-as.character(data_participant_level$ID)
data$ID2<-as.character(data$ID)
dplyr::filter_(data, ID2 %in% target)
? filter_
df <- data.frame(days = c(88, 11, 2, 5, 22, 1, 222, 2), name = c("Lynn", "Tom", "Chris", "Lisa", "Kyla", "Tom", "Lynn", "Lynn"))
# Three lines
target <- c("Tom", "Lynn")
index <- df$name %in% target
df[index, ]
# One line
df[df$name %in% c("Tom", "Lynn"), ]
detach("package:dplyr", unload=TRUE)
data[data$ID %in% , data_participant_level$ID]
data[data$ID %in% data_participant_level$ID, ]
data <-data[data$ID %in% data_participant_level$ID, ]
View(data)
