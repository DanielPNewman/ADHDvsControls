ezPlot2(boot, x=Hemisphere, split=Hemifield, col=Group)
setwd(("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_R"))
####################################
#######  How to use ################
####################################
# 1) Install the packages and software specified below. (consider also updating all installed packages by chosing Update on the Packages tab)
# 2) Set the working directory (setwd) above, and directory where you have "data_ParticipantLevel", "master_matrix_R" and "ID_vector" saved
# 3) Hit Knit Word (or Knit HTML)! (Output can take while due to bootstrapping the robust effect size and calculating the Bayesian Highest Density Iinterval)
####################################
######  FIRST TIME ONLY ############
####################################
#Remove # in front of the line below and run the code. Replace the # after installing the packages, otherwise the R markdown script will give errors.
# install.packages(c("MASS", "akima", "robustbase", "cobs", "robust", "mgcv", "scatterplot3d", "quantreg", "rrcov", "lars", "pwr", "trimcluster", "mc2d", "psych", "Rfit","MBESS", "BayesFactor", "PoweR", "ggplot2", "reshape2", "plyr", "devtools", "rmarkdown","gmodels", "HLMdiag", "car", "gridExtra", "bootES", "BEST","foreign","nlme","pastecs","multcomp","ggplot2","compute.es","ez","lattice","lme4","effects","diagram","png", "grid"))
#Installation of the robust statistics package: Remove # in front of each of 4 lines below and run the code. Replace the # after installing the packages, otherwise the R markdown script will give errors.
# install.packages("devtools")
# library("devtools")
# install_github("mrxiaohe/WRScpp")
# install_github("nicebread/WRS", subdir="pkg")
#Download and install JAGS to calculate Bayesian HDI: http://sourceforge.net/projects/mcmc-jags/
###################################################################################################################################
## Install relevant libraries
library(foreign)
library(car)
library(nlme)
library(ggplot2)
library(pastecs)
library(psych)
library(plyr)
library(multcomp)
library(reshape2)
library(compute.es)
library(ez)
library(lattice)
library(lme4)
library(png)
library(grid)
###### Import single trial data:
# data <- read.csv("C:/GitHub/ADHDvsControls/Analyses Scripts_Matlab/master_matrix_R.csv", header=FALSE)
data <- read.csv("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_Matlab/master_matrix_R.csv", header=FALSE)
#Import IDs:
# ID <- read.table("C:/GitHub/ADHDvsControls/Analyses Scripts_Matlab/ID_vector.csv", quote="\"")
ID <- read.table("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_Matlab/ID_vector.csv", quote="\"")
data$ID<-data[,1]
#Replace the participant numbers with IDs:
data[,1]<-ID[,1]
#Remove the seperate ID vector now it has been included into data dataframe
rm(ID)
drops <- c("ID")
data<-data[,!(names(data) %in% drops)]
###### Import data_ParticipantLevel:
# data_participant_level <- read.csv("C:/GitHub/ADHDvsControls/Analyses Scripts_Matlab/participant_level_matrix.csv", header=FALSE)
data_participant_level <- read.csv("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_Matlab/participant_level_matrix.csv", header=FALSE)
#remove the RT measures that were calculated from ERP script - better to extract/colapse RT from the single-trial data_participant_level
data_participant_level<-data_participant_level[,-c(1:4)]
#Import IDs:
# ID <- read.table("C:/GitHub/ADHDvsControls/Analyses Scripts_Matlab/IDs.csv", quote="\"")
ID <- read.csv("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_Matlab/IDs.csv", header=F)
ID<-rename(ID,c("V1"="ID"))
data_participant_level$ID<-ID$ID
rm(ID)
# drops <- c("ID")
# data_participant_level<-data_participant_level[,!(names(data_participant_level) %in% drops)]
#import demographic data
# Demographics<-read.csv("C:/GitHub/ADHDvsControls/Analyses Scripts_R/ADHD_Control_Demographics_etc.csv", header=T)
Demographics<-read.csv("C:/Users/Dan/Documents/GitHub/ADHDvsControls/Analyses Scripts_R/ADHD_Control_Demographics_etc.csv", header=T)
#Merge Demographics into data_participant_level:
data_participant_level <- merge(data_participant_level, Demographics, by.x = "ID", by.y = "ID")
rm(Demographics)
#Rename data columns:
data<-rename(data, c("V1"="ID", "V2"="Group","V3"="TotalTrialNumber","V4"="Trial","V5"="ITI",
"V6"="Hemifield","V7"="Accuracy","V8"="RT",
"V9"="Blinkneg500to0","V10"="Blinkneg100_100PR","V11"="Blinkneg100_450",
"V12"="LeftFixBreakneg500_0","V13"="LeftFixBreakneg100_100PR","V14"="LeftFixBreakneg100_450",
"V15"="RightFixBreakneg500_0","V16"="RightFixBreakneg100_100PR","V17"="RightFixBreakneg100_450",
"V18"="BothFixBreakneg500_0","V19"="BothFixBreakneg100_100PR","V20"="BothFixBreakneg100_450",
"V21"="Art_neg500_0","V22"="Art_neg100_100PR","V23"="BLANK",
"V24"="RejectedTrial","V25"="Art_neg100_450","V26"="PreAlphaPowerLH",
"V27"="PreAlphaPowerRH","V28"="PreAlphaAsym","V29"="PrePupilDiameter", "V30"="N2c_GA","V31"="N2i_GA",
"V32"="RespLockedCPPSlope","V33"="StimLockedCPPSlope", "V34"="N2cPeakLatency", "V35"="CPPHalfPeakLatency",
"V36"="N2c_PA","V37"="N2i_PA"))   #NOTE: FOR N2c/i, the "_GA" or "_PA" suffix indicates whether N2c/i is measured with a measurement window based                                                        #on Grand average (GA) peak N2c/i latency, or based on Participant level average (PA) peak N2c/i latency
#Make the required columns into factors:
data$Group <- factor(data$Group)
data$ITI <- factor(data$ITI)
data$Hemifield <- factor(data$Hemifield)
# data$Sex <- factor(data$Sex)
data$Accuracy <- factor(data$Accuracy)
#Rename factor Levels:
data$Group <- revalue(data$Group, c("1"="ADHD", "2"="Control"))
data$ITI <- revalue(data$ITI, c("1"="3060ms", "2"="5170ms", "3"="7290ms"))
data$Hemifield <- revalue(data$Hemifield, c("1"="Left", "2"="Right"))
# data$Sex <- revalue(data$Sex, c("1"="Male", "2"="Female"))
data$Accuracy <- revalue(data$Accuracy, c("1"="Hit", "0"="Miss"))
#Re-class required vectors into Logicals:
data$Blinkneg500to0<-as.logical(data$Blinkneg500to0)
data$Blinkneg100_100PR<-as.logical(data$Blinkneg100_100PR)
data$Blinkneg100_450<-as.logical(data$Blinkneg100_450)
data$LeftFixBreakneg500_0<-as.logical(data$LeftFixBreakneg500_0)
data$LeftFixBreakneg100_100PR<-as.logical(data$LeftFixBreakneg100_100PR)
data$LeftFixBreakneg100_450<-as.logical(data$LeftFixBreakneg100_450)
data$RightFixBreakneg500_0<-as.logical(data$RightFixBreakneg500_0)
data$RightFixBreakneg100_100PR<-as.logical(data$RightFixBreakneg100_100PR)
data$RightFixBreakneg100_450<-as.logical(data$RightFixBreakneg100_450)
data$BothFixBreakneg500_0<-as.logical(data$BothFixBreakneg500_0)
data$BothFixBreakneg100_100PR<-as.logical(data$BothFixBreakneg100_100PR)
data$BothFixBreakneg100_100PR<-as.logical(data$BothFixBreakneg100_100PR)
data$BothFixBreakneg100_450<-as.logical(data$BothFixBreakneg100_450)
data$Art_neg500_0<-as.logical(data$Art_neg500_0)
data$Art_neg100_100PR<-as.logical(data$Art_neg100_100PR)
data$Art_neg100_450<-as.logical(data$Art_neg100_450)
data$RejectedTrial<-as.logical(data$RejectedTrial)
#Order any ordinal factors (may have to do this the "trail" or later too)
# by defult R uses polynomial contrasts for ordered factors, I'd rather treat light as unordered and to "treatment" contrasts, i.e. Low vs Med, Low vs High
data$ITI <- ordered(data$ITI, levels = c("3060ms", "5170ms", "7290ms"))
# data$Trial <- ordered(data$Trial)
###############Data Cleaning For Single Trial Data######################
#Check number of Trials for each participant by running the function 'length',
#on "data$RT" for each group, broken down by ID + Light
num_trials1 <- ddply(data, c("ID"), summarise,
Trials    = length(RT))
mean(num_trials1$Trials)
Accuracy_checker <- ddply(data, c("ID"), summarise,
Hits  = sum(Accuracy=="Hit"),
Misses = sum(Accuracy=="Miss"))
Accuracy_checker$Total=Accuracy_checker$Hits+Accuracy_checker$Misses
Accuracy_checker$Accuracy=(Accuracy_checker$Hits/Accuracy_checker$Total)*100
summary(Accuracy_checker$Accuracy)
#Remove rejected trials with trigger conflicts
data<-data[!data$RejectedTrial,]
#Remove trials where RT=0 (i.e. they did not respond)
data<-data[data$RT!=0,]
#Remove trials where RT longer than 1000ms (i.e. after target finished)
data<-data[data$RT<2000,]
#Remove trials where RT faster than 100ms (i.e. too fast must be false alarm)
data<-data[data$RT>200,]
#Remove trials with missing values :
data<-data[complete.cases(data),]
############################################ Log transform:
#################################################################################################################################
data$log_RT<-log(data$RT) #log
#####Z-score each participant's log_RT data ####
#calculate mean and sd
m <- tapply(data$log_RT,data$ID,mean)
s <- sqrt(tapply(data$log_RT,data$ID,var))
#calculate log_RT.Z and save it inside data.frame
data$log_RT.Z <- (data$log_RT-m[data$ID])/s[data$ID]
#check that Z scores have mean=0 and std=1
log_RT.Z_checker <- ddply(data, c("ID"), summarise,
N    = length(log_RT.Z ),
mean = round(mean(log_RT.Z )),
sd   = sd(log_RT.Z ),
se   = sd / sqrt(N))
summary(log_RT.Z_checker$mean)
#Remove trials where absolute log_RT.Z>3 (i.e. remove outlier RTs)
data<-data[!abs(data$log_RT.Z)>3,]
#plot again after outlier removal:
ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
hist_RT <- ggplot(data, aes(RT))  + geom_histogram(aes(y=..count..), colour="black", fill="white")
hist_RT + facet_wrap(~ ID)
#Make PostAlpha contralateral (PostAlpha_c) and -Ipsilateral (PostAlpha_i) variables:
A<-data$Hemifield=="Left"
data$PostAlpha_c[A]<-data$RightHemi_PostAlpha[A]
data$PostAlpha_c[!A]<-data$LeftHemi_PostAlpha[!A]
data$PostAlpha_i[!A]<-data$LeftHemi_PostAlpha[!A]##################### MATLAB script doesn't extract this yet!!!
data$PostAlpha_i[A]<-data$RightHemi_PostAlpha[A]
rm(A)
#################################################################################################################################
#################################################################################################################################
#################################################################################################################################
#################################################################################################################################
#Rename data_participant_level columns of data_participant_level:
data_participant_level<-rename(data_participant_level, c("V5"="ValidPreAlphaTrials",
"V6"="ValidN2TrialsTrials","V7"="ValidCPPTrials","V8"="PreAlpha_LeftHemi",
"V9"="PreAlpha_RightHemi","V10"="N2c_LeftTarget_GA","V11"="N2c_RightTarget_GA",
"V12"="N2i_LeftTarget_GA","V13"="N2i_RightTarget_GA","V14"="AlphaDesync_LeftHemi_LeftTarget",
"V15"="AlphaDesync_LeftHemi_RightTarget","V16"="AlphaDesync_RightHemi_LeftTarget",
"V17"="AlphaDesync_RightHemi_RightTarget",
"V18"="CPPonset_LeftTarget","V19"="CPPonset_RightTarget","V20"="N2c_latency_LeftTarget",
"V21"="N2c_latency_RightTarget","V22"="N2i_latency_LeftTarget","V23"="N2i_latency_RightTarget",
"V24"="CPPslope_LeftTarget","V25"="CPPslope_RightTarget","V26"="FrontalNeg_slope_LeftTarget",
"V27"="FrontalNeg_slope_RightTarget", "V28"="ADHD_Control",
"V29"="N2c_LeftTarget_PA","V30"="N2c_RightTarget_PA",
"V31"="N2i_LeftTarget_PA","V32"="N2i_RightTarget_PA"))
#NOTE: FOR N2c/i, the "_GA" or "_PA" suffix indicates whether N2c/i is measured with a measurement window based                                                        #on Grand average (GA) peak N2c/i latency, or based on Participant level average (PA) peak N2c/i latency
write.csv(data_participant_level, file = "participant_level_data.csv", row.names = F)
#Look at Column names:
colnames(data_participant_level)
#Make the required columns into factors:
data_participant_level$Group <- factor(data_participant_level$Group)
#Rename factor Levels:
data_participant_level$Group <- revalue(data_participant_level$Group, c("1"="ADHD", "2"="Control"))
###Re-class required vectors into Logicals:
#data_participant_level$Blinkneg500to0<-as.logical(data_participant_level$Blinkneg500to0)
#Exclude the following participants from the ADHD group due to clinical cuttoff filter_CPRS_N_B
# AD69C', 'AD59C', 'AD27C', 'AD51C', 'AD98C'
#Exclude the following control participants:
#'C14', 'C259' for filter_CPRS_N_B; %C194 not enough valid trials
#Single trial
toBeRemoved<-which(data$ID=="AD69C" | data$ID=="AD59C" | data$ID=="AD27C" | data$ID=="AD51C" | data$ID=="AD98C" | data$ID=="C14" | data$ID=="C259"|  data$ID=="C194")
if (any(toBeRemoved)) {
data<-data[-toBeRemoved,]
}
#Participant level
toBeRemoved<-which(data_participant_level$ID=="AD69C" | data_participant_level$ID=="AD59C" | data_participant_level$ID=="AD27C" | data_participant_level$ID=="AD51C" | data_participant_level$ID=="AD98C" | data_participant_level$ID=="C14" | data_participant_level$ID=="C259"|  data_participant_level$ID=="C194")
if (any(toBeRemoved)) {
data_participant_level<-data_participant_level[-toBeRemoved,]
}
data2<-data[!data$LeftFixBreakneg100_100PR  &!data$RightFixBreakneg100_100PR,]
########################### Multi-level Models ##########################
# RT_random_intercepts_only<-glmer(RT ~ 1 + (1 | Group/ID) +(1|ITI) + (1|Hemifield) + (1|Trial), data = data2, family = Gamma(link = log), na.action = na.omit)
RT_random_intercepts_only<-lmer(log(RT) ~ 1 + (1 | ID) +(1|ITI) + (1|Hemifield) + (1|Trial), data = data2, REML=FALSE, na.action = na.omit)
RT_Group<-update(RT_random_intercepts_only, .~. + Group)
RT_Hemifield<-update(RT_Group, .~. + Hemifield)
RT_HemifieldbyGroup<-update(RT_Hemifield, .~. + Hemifield:Group)
anova(RT_random_intercepts_only, RT_Group, RT_Hemifield, RT_HemifieldbyGroup)
#Check for time-on-task effects:
RT_TOT<-update(RT_Hemifield, .~. + Trial)
RT_HemifieldbyTOT<-update(RT_TOT, .~. + Hemifield:Trial)
RT_GroupbyTOT<-update(RT_HemifieldbyTOT, .~. + Trial:Group)
RT_HemifieldbyGroupbyTOT<-update(RT_GroupbyTOT, .~. + Hemifield:Group:Trial)
anova(RT_HemifieldbyGroup, RT_TOT,RT_HemifieldbyTOT, RT_GroupbyTOT, RT_HemifieldbyGroupbyTOT)
#Plot the Hemifield x Group x TOT effect using the raw data
ggplot(data2, aes(x=data2$Trial, y=data2$RT,fill=Hemifield,colour=Hemifield)) +
stat_smooth(method="glm",level = 0.95,size=1) +
scale_fill_manual(name="Target\nHemifield",  breaks=c("Left", "Right"), labels=c(" Left", " Right"), guide = guide_legend(reverse=TRUE), values=c("red", "green")) +
scale_colour_manual(name="Target\nHemifield",  breaks=c("Left", "Right"), labels=c(" Left", " Right"), guide = guide_legend(reverse=TRUE), values=c("red", "green")) +
ylab("RT (ms)") +  xlab("Time On Task (200 trials)") + coord_cartesian(ylim = c(700, 900), xlim = c(-10, 200))+
theme(axis.title.x = element_text(face="bold", size=14),
axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
theme(axis.title.y = element_text(face="bold", size=14),
axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
theme(legend.title = element_text(size=14, face="bold")) +
theme(legend.text = element_text(size = 12, face = "bold")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"))  + facet_wrap(~ Group)
data2$TwoBins<-cut(data2$Trial, c(0,100,220), labels = c("First_Half", "Second_Half"))
summary(data2$TwoBins)
### For Controls, effect of target hemifield during the first half of the session:
summary(glht(lmer(log(RT) ~ Hemifield + (1 | ID) +(1|ITI) + (1|Hemifield) + (1|Trial), data = data2[data2$Group=="Control" & data2$TwoBins=="First_Half",], REML=FALSE, na.action = na.omit)))
### For Controls, effect of target hemifield during the 2nd half of the session:
summary(glht(lmer(log(RT) ~ Hemifield + (1 | ID) +(1|ITI) + (1|Hemifield) + (1|Trial), data = data2[data2$Group=="Control" & data2$TwoBins=="Second_Half",], REML=FALSE, na.action = na.omit)))
### For ADHD, effect of target hemifield during the first half of the session:
summary(glht(lmer(log(RT) ~ Hemifield + (1 | ID) +(1|ITI) + (1|Hemifield) + (1|Trial), data = data2[data2$Group=="ADHD" & data2$TwoBins=="First_Half",], REML=FALSE, na.action = na.omit)))
### For ADHD, effect of target hemifield during the 2nd half of the session:
summary(glht(lmer(log(RT) ~ Hemifield + (1 | ID) +(1|ITI) + (1|Hemifield) + (1|Trial), data = data2[data2$Group=="ADHD" & data2$TwoBins=="Second_Half",], REML=FALSE, na.action = na.omit)))
#Bin trials for TOT into 2 bins - First half of trials vs 2nd half
source("summarySE.R")
source("summarySEwithin.R") #function to calculate Std.Er of mean
source("normDataWithin.R")
plotdata <- summarySEwithin(data2, measurevar="RT", withinvars=c("Hemifield", "TwoBins"), betweenvars="Group", idvar="ID")
ggplot(plotdata, aes(x=TwoBins, y=RT, fill=Hemifield)) +
geom_bar(position=position_dodge(.9), colour="Black", stat="identity") +
geom_errorbar(position=position_dodge(.9), width=.3, aes(ymin=RT-se, ymax=RT+se)) + #can change "se" to "ci" if I want to use 95%ci instead
geom_hline(yintercept=0) +  coord_cartesian(ylim = c(700, 900)) +
xlab("Hemifield") + ylab("RT (ms)") +
theme(axis.title.x = element_text(face="bold", size=12),
axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
theme(axis.title.y = element_text(face="bold", size=12),
axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
theme(legend.title = element_text(size=11, face="bold")) +
theme(legend.text = element_text(size = 11, face = "bold")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black")) + facet_wrap(~ Group)
#Bin trials for TOT into 2 bins - First half of trials vs 2nd half
source("summarySE.R")
source("summarySEwithin.R") #function to calculate Std.Er of mean
source("normDataWithin.R")
plotdata <- summarySEwithin(data2, measurevar="RT", withinvars=c("Hemifield", "TwoBins"), betweenvars="Group", idvar="ID")
ggplot(plotdata, aes(x=TwoBins, y=RT, fill=Hemifield)) +
geom_bar(position=position_dodge(.9), colour="Black", stat="identity") +
geom_errorbar(position=position_dodge(.9), width=.3, aes(ymin=RT-se, ymax=RT+se)) + #can change "se" to "ci" if I want to use 95%ci instead
geom_hline(yintercept=0) +  coord_cartesian(ylim = c(700, 900)) +
xlab("Hemifield") + ylab("RT (ms)") +
theme(axis.title.x = element_text(face="bold", size=12),
axis.text.x  = element_text(face="bold", angle=0,  size=12)) +
theme(axis.title.y = element_text(face="bold", size=12),
axis.text.y  = element_text(angle=0, vjust=0.5, size=12)) +
theme(legend.title = element_text(size=11, face="bold")) +
theme(legend.text = element_text(size = 11, face = "bold")) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black")) + facet_wrap(~ Group)
DF<-data.frame(data$ID, data$Group, data$ITI, data$Hemifield, data$PreAlphaPowerLH,data$PreAlphaPowerRH,data$Trial, data$Art_neg500_0
, data$LeftFixBreakneg500_0 , data$RightFixBreakneg500_0 , data$Blinkneg500to0)
names(DF) <- c("ID", "Group",    "ITI",	"Hemifield","PreAlphaPowerLH","PreAlphaPowerRH","Trial", "Art_neg500_0", "LeftFixBreakneg500_0", "RightFixBreakneg500_0", "Blinkneg500to0")
DF$LeftHemi<-rep("Left",length(DF[,1]))
DF$RightHemi<-rep("Right",length(DF[,1]))
DF_LeftHemi<-subset(DF, select=c(ID, Group, ITI, Hemifield,PreAlphaPowerLH,LeftHemi,Trial,Art_neg500_0,LeftFixBreakneg500_0,RightFixBreakneg500_0,Blinkneg500to0))
DF_RightHemi<-subset(DF, select=c(ID, Group, ITI, Hemifield,PreAlphaPowerRH,RightHemi,Trial,Art_neg500_0,LeftFixBreakneg500_0,RightFixBreakneg500_0,Blinkneg500to0))
names(DF_LeftHemi)[names(DF_LeftHemi)=="LeftHemi"] <- "Hemisphere"
names(DF_RightHemi)[names(DF_RightHemi)=="RightHemi"] <- "Hemisphere"
names(DF_LeftHemi)[names(DF_LeftHemi)=="PreAlphaPowerLH"] <- "PreAlphaPower"
names(DF_RightHemi)[names(DF_RightHemi)=="PreAlphaPowerRH"] <- "PreAlphaPower"
DF<-rbind(DF_LeftHemi,DF_RightHemi)
rm(DF_LeftHemi,DF_RightHemi)
DF$Hemisphere <- factor(DF$Hemisphere)
DF<-DF[!DF$Art_neg500_0 &!DF$Blinkneg500to0 &!DF$LeftFixBreakneg500_0 &!DF$RightFixBreakneg500_0,]
DF<-DF[DF$PreAlphaPower!=0,]
#Remove trials with missing values :
DF<-DF[complete.cases(DF),]
DF$log_PreAlphaPower<-log(DF$PreAlphaPower) #log
#Kick out outliers
#####Z-score each participant's log_PreAlphaPower inside Hemisphere####
DF$IDbyHemisphere<-interaction(DF$ID, DF$Hemisphere)
#calculate mean and sd
m <- tapply(DF$log_PreAlphaPower,DF$IDbyHemisphere,mean,na.rm=T)
s <- sqrt(tapply(DF$log_PreAlphaPower,DF$IDbyHemisphere,var,na.rm=T))
#calculate log_PreAlphaPower.Z and save it inside DF.frame
DF$log_PreAlphaPower.Z <- (DF$log_PreAlphaPower-m[DF$IDbyHemisphere])/s[DF$IDbyHemisphere]
#check that Z scores have mean=0 and std=1
log_PreAlphaPower.Z_checker <- ddply(DF, c("ID", "Hemisphere"), summarise,
N    = length(log_PreAlphaPower.Z),
mean = round(mean(log_PreAlphaPower.Z)),
sd   = sd(log_PreAlphaPower.Z ),
se   = sd / sqrt(N) )
##Remove trials where absolute log_PreAlphaPower.Z>3 (i.e. remove outlier log_PreAlphaPowers)
DF<-DF[!abs(DF$log_PreAlphaPower.Z)>3,]
# REML=FALSE,
cat("Number of Observations for modle:")
print(dim(DF)[1])
############ Modle the effects of Group, and Hemisphere on Pre-target Alpha Power ###########
PreAlphaPower_random_intercepts_only<-lmer(log(PreAlphaPower) ~ 1 + (1 | ID/Hemisphere) +(1|ITI) + (1|Trial), data = DF,  na.action = na.omit, REML=F)
PreAlphaPower_Group<-update(PreAlphaPower_random_intercepts_only, .~. + Group)
PreAlphaPower_Hemisphere<-update(PreAlphaPower_Group, .~. + Hemisphere)
PreAlphaPower_GroupbyHemisphere<-update(PreAlphaPower_Hemisphere, .~. + Group*Hemisphere)
PreAlphaPower_TOT<-update(PreAlphaPower_GroupbyHemisphere, .~. + Trial)
PreAlphaPower_GroupbyTOT <- update(PreAlphaPower_TOT, .~. + Group*Trial)
PreAlphaPower_HemispherebyTOT <- update(PreAlphaPower_GroupbyTOT, .~. + Hemisphere*Trial)
PreAlphaPower_GroupbyHemispherebyTOT<-update(PreAlphaPower_HemispherebyTOT, .~. + Group*Hemisphere*Trial)
anova(PreAlphaPower_random_intercepts_only, PreAlphaPower_Group,PreAlphaPower_Hemisphere,PreAlphaPower_GroupbyHemisphere,PreAlphaPower_TOT,PreAlphaPower_GroupbyTOT, PreAlphaPower_HemispherebyTOT, PreAlphaPower_GroupbyHemispherebyTOT)
eff.GroupbyHemispherebyTOT <- Effect(c("Group", "Hemisphere", "Trial"), PreAlphaPower_GroupbyHemispherebyTOT)
plot(eff.GroupbyHemispherebyTOT, layout=c(2,1), main=NULL, rug=F, multiline =T, alternating=T, z.var="Hemisphere", ticks.x=NULL,ylim=c(0.9,1.16), xlab="Time-on-task (trial)", ylab="Alpha Power (uV)")
require(effects)
eff.GroupbyHemispherebyTOT <- Effect(c("Group", "Hemisphere", "Trial"), PreAlphaPower_GroupbyHemispherebyTOT)
plot(eff.GroupbyHemispherebyTOT, layout=c(2,1), main=NULL, rug=F, multiline =T, alternating=T, z.var="Hemisphere", ticks.x=NULL,ylim=c(0.9,1.16), xlab="Time-on-task (trial)", ylab="Alpha Power (uV)")
plot(eff.GroupbyHemispherebyTOT, layout=c(2,1), main=NULL, rug=F, multiline =T, alternating=T, z.var="Hemisphere", ticks.x=NULL,ylim=c(0.9,1.16), xlab="Time-on-task (trial)", ylab="Alpha Power (uV)", ci.style="bars")
residuals_PreAlphaPower_GroupbyHemispherebyTOT=residuals(PreAlphaPower_GroupbyHemispherebyTOT)
plot(residuals_PreAlphaPower_GroupbyHemispherebyTOT)
qqnorm(residuals_PreAlphaPower_GroupbyHemispherebyTOT)
qqline(residuals_PreAlphaPower_GroupbyHemispherebyTOT)
hist(residuals_PreAlphaPower_GroupbyHemispherebyTOT)
contrast.matrix_HemispherebyTOT<-rbind(
"LeftHemisphere:TOT vs RightHemisphere:TOT"  =c(0,0,0,1))
#Test for Hemisphere*TOT effect in Controls only
PreAlphaPower_random_intercepts_only_Control<-lmer(log(PreAlphaPower) ~ 1 + (1 | ID/Hemisphere) +(1|ITI) + (1|Trial), data = DF[DF$Group=="Control",],  na.action = na.omit, REML=F)
PreAlphaPower_Hemisphere_Control<-update(PreAlphaPower_random_intercepts_only_Control, .~. + Hemisphere)
PreAlphaPower_TOT_Control<-update(PreAlphaPower_Hemisphere_Control, .~. + Trial)
PreAlphaPower_HemispherebyTOT_Control <- update(PreAlphaPower_TOT_Control, .~. + Hemisphere*Trial)
anova(PreAlphaPower_random_intercepts_only_Control, PreAlphaPower_Hemisphere_Control, PreAlphaPower_TOT_Control, PreAlphaPower_HemispherebyTOT_Control)
#Test for Hemisphere*TOT effect in ADHD only
PreAlphaPower_random_intercepts_only_ADHD<-lmer(log(PreAlphaPower) ~ 1 + (1 | ID/Hemisphere) +(1|ITI) + (1|Trial), data = DF[DF$Group=="ADHD",],  na.action = na.omit, REML=F)
PreAlphaPower_Hemisphere_ADHD<-update(PreAlphaPower_random_intercepts_only_ADHD, .~. + Hemisphere)
PreAlphaPower_TOT_ADHD<-update(PreAlphaPower_Hemisphere_ADHD, .~. + Trial)
PreAlphaPower_HemispherebyTOT_ADHD <- update(PreAlphaPower_TOT_ADHD, .~. + Hemisphere*Trial)
anova(PreAlphaPower_random_intercepts_only_ADHD, PreAlphaPower_Hemisphere_ADHD, PreAlphaPower_TOT_ADHD, PreAlphaPower_HemispherebyTOT_ADHD)
summary(glht(PreAlphaPower_HemispherebyTOT_ADHD, contrast.matrix_HemispherebyTOT))
#Control
summary(glht(PreAlphaPower_HemispherebyTOT_Control, contrast.matrix_HemispherebyTOT))
